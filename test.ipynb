{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e59204",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Define Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13302c1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# --- DEFINE CONSTANTS ---\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Set the path to your training data directory\u001b[39;00m\n\u001b[32m     10\u001b[39m DATA_DIR = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mSreeneel Chavidi\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mOneDrive\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.vs code\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.vs code\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDNA-Proj\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdataset-trafficsigns\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mIndian-Traffic Sign-Dataset\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mImages\u001b[39m\u001b[33m'\u001b[39m \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:468\u001b[39m\n\u001b[32m    466\u001b[39m     importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mtf_keras.src.optimizers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    467\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeras.src.optimizers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m    470\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2032.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tf_keras \u001b[38;5;28;01mas\u001b[39;00m _tf_keras\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks \u001b[38;5;28;01mas\u001b[39;00m callbacks\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\activations\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize \u001b[38;5;28;01mas\u001b[39;00m deserialize\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get \u001b[38;5;28;01mas\u001b[39;00m get\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize \u001b[38;5;28;01mas\u001b[39;00m serialize\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\src\\__init__.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\Project_dna\\.venv\\Lib\\site-packages\\keras\\src\\layers\\__init__.py:204\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconv_lstm1d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvLSTM1D\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconv_lstm2d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvLSTM2D\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconv_lstm3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvLSTM3D\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRU\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRUCell\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1022\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1118\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1217\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# --- DEFINE CONSTANTS ---\n",
    "# Set the path to your training data directory\n",
    "DATA_DIR = r'C:\\Users\\Sreeneel Chavidi\\OneDrive\\Desktop\\.vs code\\.vs code\\DNA-Proj\\dataset-trafficsigns\\Indian-Traffic Sign-Dataset\\Images' \n",
    "\n",
    "# Define the desired image dimensions\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "\n",
    "# Get the number of classes (subdirectories)\n",
    "NUM_CLASSES = len(os.listdir(DATA_DIR))\n",
    "\n",
    "print(f\"Dataset Path: {DATA_DIR}\")\n",
    "print(f\"Image Dimensions: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f06a1",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3553f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preprocessing data... Please wait.\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop over each class folder (from 0 to NUM_CLASSES-1)\n",
    "for class_id in range(NUM_CLASSES):\n",
    "    class_path = os.path.join(DATA_DIR, str(class_id))\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if not os.path.isdir(class_path): \n",
    "        continue\n",
    "    \n",
    "    # Loop over each image in the class folder\n",
    "    for img_name in os.listdir(class_path):\n",
    "        try:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            \n",
    "            # Read the image in color\n",
    "            image = cv2.imread(img_path)\n",
    "            \n",
    "            # Resize the image to the desired dimensions\n",
    "            image_resized = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            \n",
    "            # Append the processed image and its label\n",
    "            images.append(image_resized)\n",
    "            labels.append(class_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# --- DATA CONVERSION AND NORMALIZATION ---\n",
    "\n",
    "# Convert lists to NumPy arrays for efficient processing\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values from [0, 255] to [0, 1]\n",
    "images = images / 255.0\n",
    "\n",
    "print(f\"Shape of images array: {images.shape}\")\n",
    "print(f\"Shape of labels array: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d3aa2e",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis: Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZE CLASS DISTRIBUTION ---\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(labels, bins=NUM_CLASSES, rwidth=0.8)\n",
    "plt.title('Distribution of Traffic Sign Classes')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5720be",
   "metadata": {},
   "source": [
    "### 4. Split Data and One-Hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88865012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SPLIT THE DATA ---\n",
    "# Using 80% for training and 20% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42, # for reproducibility\n",
    "    stratify=labels # ensures the split has a similar class distribution\n",
    ")\n",
    "\n",
    "# --- ONE-HOT ENCODE THE LABELS ---\n",
    "# This converts class vectors (integers) to binary class matrices.\n",
    "# Example: label '3' with 5 classes becomes [0, 0, 0, 1, 0]\n",
    "y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "\n",
    "print(\"\\n--- Data Splitting and Encoding Complete ---\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10adcbfa",
   "metadata": {},
   "source": [
    "### 5. Build and Compile the CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# --- DEFINE THE CNN MODEL ARCHITECTURE ---\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First Convolutional Block\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Second Convolutional Block\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "# Flatten the feature maps to a 1D vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Dense Layer\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Output Layer - Must have the same number of units as NUM_CLASSES\n",
    "# Your output shows 58 classes, so we use that number here.\n",
    "model.add(Dense(units=58, activation='softmax'))\n",
    "\n",
    "\n",
    "# --- COMPILE THE MODEL ---\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- DISPLAY THE MODEL SUMMARY ---\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea27dcb",
   "metadata": {},
   "source": [
    "### 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdfc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAIN THE MODEL ---\n",
    "\n",
    "print(\"Starting model training... This will take some time.\")\n",
    "\n",
    "# We'll start with 15 epochs. An epoch is one full pass through the entire training data.\n",
    "epochs = 15\n",
    "batch_size = 32 # The model will look at 32 images at a time\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val) # We use the validation data to check how well the model is generalizing\n",
    ")\n",
    "\n",
    "print(\"\\nModel training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3e079",
   "metadata": {},
   "source": [
    "### 7. Visualize Training History (Accuracy and Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- PLOT THE TRAINING & VALIDATION ACCURACY ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# --- PLOT THE TRAINING & VALIDATION LOSS ---\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50355f7",
   "metadata": {},
   "source": [
    "### 8. Save the Final Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a single HDF5 file.\n",
    "model.save('my_traffic_sign_model.h5')\n",
    "\n",
    "print(\"Model saved successfully as my_traffic_sign_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
